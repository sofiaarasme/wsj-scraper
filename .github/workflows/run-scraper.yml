# Workflow name
name: Fetch WSJ daily value extraction

# ---------------------------------
# TRIGGER CONFIGURATION
# ---------------------------------
on:
  # Allows to run this workflow manually from the Actions tab on GitHub.
  workflow_dispatch:

  # Runs the workflow on a schedule.
  schedule:
    # This uses CRON syntax. The schedule is in UTC.
    # Nebraska is Central Time (CT), which is UTC-5 (CDT).
    # 11 PM CDT (UTC-5) is 4:00 AM UTC the next day.
    # This schedule runs at both 4 AM and 5 AM UTC to cover both standard and daylight saving time.
    - cron: '0 4,5 * * *'

# ---------------------------------
# JOB CONFIGURATION
# ---------------------------------
jobs:
  # The job is named 'build'
  build:
    # Specifies the runner environment. 'ubuntu-latest' is a standard.
    runs-on: ubuntu-latest

    # A sequence of tasks that the job will execute.
    steps:
      # Step 1
      # This downloads the Python scripts and requirements.txt into the runner environment.
      - name: Checkout repository
        uses: actions/checkout@v4

      # Step 2
      # This installs a specific version of Python for the job to use.
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      # Step 3: Install the Python dependencies listed in requirements.txt.
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Step 4: Install the necessary browsers for Playwright.
      - name: Install Playwright Browsers
        run: playwright install --with-deps

      # Step 5: Create the necessary credential and session files from GitHub Secrets.
      
      - name: Create Google Credentials File
        env:
          # Map the GitHub Secret to an environment variable named CREDENTIALS_JSON
          CREDENTIALS_JSON: ${{ secrets.GOOGLE_CREDENTIALS }}
        run: echo "$CREDENTIALS_JSON" > google_creds.json

      - name: Create WSJ Session File
        env:
          # Map the GitHub Secret to an environment variable named SESSION_JSON
          SESSION_JSON: ${{ secrets.WSJ_SESSION_STATE }}
        run: echo "$SESSION_JSON" > session_state.json

      - name: Create WSJ Session File
        run: echo "${{ secrets.WSJ_SESSION_STATE }}" > session_state.json

      # Step 6: Run the main Python scraper script.
      - name: Run Python Scraper
        env:
          SHEET_ID: ${{ secrets.SHEET_ID }}
          GOOGLE_APPLICATION_CREDENTIALS: ./google_creds.json
        run: python wsj_value_fetcher.py
        
